{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Generalized Linear Models with Quantopo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalized linear models are the simplest instance of link-based statistical\n",
    "models, which are based on the underlying geometry of an outcome’s underlying\n",
    "probability distribution (typically from the exponential family).\n",
    "\n",
    "Machine learning algorithms provide alternative ways to minimize a model’s sum\n",
    "of square error (error between predicted values and actual values of a test set).\n",
    "\n",
    "However, some deep results regarding the exponential family’s relation to affine\n",
    "connections in differential geometry provide a possible alternative to link\n",
    "functions:\n",
    "1. Algorithms that either continuously deform the outcome distribution from known results\n",
    "2. Algorithms that superpose all possible distributions and collapse to fit a dataset \n",
    "<br>\n",
    "-Leveraging the fact that some quantum computer gates, such as the non-Gaussian\n",
    "transformation gate, essentially perform (1) natively and in a computationally-efficient\n",
    "way!\n",
    "\n",
    "This project provides a proof-of-concept for leveraging continuous-variable quantum circuits\n",
    "and gates to solve the affine connection problem, with benchmarking at state-of-the-art levels\n",
    "(See powerpoint presentation in quantopo/projects/QGLM/Xanadu/docs/'Quantum Generalized Linear Models.pdf'). \n",
    "\n",
    "Xanadu’s qumode formulation makes ideal for implementing quantum GLMs (See powerpoint presentation for greater detail):\n",
    "1. Ability to perform linear algebra operations on physical data representations.\n",
    "2. Non-Gaussian transformation gate provides perfect avenue to perform the affine\n",
    "transformation related to the outcome distribution without a need to specific a\n",
    "link function to approximate the geometry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages Imported:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xanadu's quantum software packages are imported: \n",
    "\n",
    "1. strawberryfields (https://strawberryfields.readthedocs.io/en/latest/installing.html) \n",
    "2. qmlt (https://qmlt.readthedocs.io/en/latest/installing.html) \n",
    "\n",
    "(1) includes the basic gates used in continuous-variable quantum citcuits and (2) is a quantum machine learning package that includes functions for building quantum neural networks and optimization parameters. \n",
    "\n",
    "Other packages:\n",
    "\n",
    "3. Tensorflow\n",
    "4. numpy\n",
    "5. pandas\n",
    "\n",
    "(3) is imported to run program on tensorflow backend-simulator. (4) and (5) are used for statistics and data structure of imported data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import strawberryfields as sf\n",
    "from strawberryfields.ops import Dgate, BSgate, Rgate, Sgate, Kgate, Interferometer\n",
    "from qmlt.tf.helpers import make_param\n",
    "from qmlt.tf import CircuitLearner\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "depth - depth of neural network (Generalized Linear Models only require 1 layer)<br>\n",
    "steps - number of training steps when training network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 1\n",
    "steps = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of circuit function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "circuit:\n",
    "\n",
    "The whole function is coded in tensorflow. It takes in a batch of data. The number of qubits is based on the number of features/columns (excluding label). In this example, dimension of features was reduced to 4 using principal component analysis.\n",
    "\n",
    "The make_param function from the qmlt package helps initialize and keep track of the gate parameters defined in the quantum neural network. See presentation in quantopo/projects/QGLM/Xanadu/docs/'Quantum Generalized Linear Models' to see how the parameters fit in the quantum neural network gates.\n",
    "\n",
    "The inner function, layer, defines the gates layout per iteration. See presentation in quantopo/projects/QGLM/Xanadu/docs/'Quantum Generalized Linear Models' to get an understanding of this layout.\n",
    "\n",
    "The circuit backend engine is initiated at the call of sf.Engine() with the number of qumodes (continuous variable qubits) passed to the engine. The with function that follows that is called by eng.run and begins the circuit run for training and testing the neural network.\n",
    "\n",
    "The parameter optimization is implemented by the call state.quad_expectation(). The output of the circuit is returned.\n",
    "\n",
    "argument:\n",
    "\n",
    "X (Tensor) - tensor of input data for training and testing neural network circuit\n",
    "\n",
    "Return:\n",
    "\n",
    "Predicted outputs with current circuit setting (Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit(X):\n",
    "    num_qubits = X.get_shape().as_list()[1]\n",
    "\n",
    "    phi_1 = make_param(name='phi_1', stdev=np.sqrt(2)/num_qubits, shape=[depth, num_qubits], regularize=False)\n",
    "    theta_1 = make_param(name='theta_1', stdev=np.sqrt(2)/num_qubits, shape=[depth, num_qubits], regularize=False)\n",
    "    a = make_param(name='a', stdev=np.sqrt(2)/num_qubits, shape=[depth, num_qubits], regularize=False, monitor=True)\n",
    "    rtheta_1 = make_param(name='rtheta_1', stdev=np.sqrt(2)/num_qubits, shape=[depth, num_qubits], regularize=False, monitor=True)\n",
    "    r = make_param(name='r', stdev=np.sqrt(2)/num_qubits, shape=[depth, num_qubits], regularize=False, monitor=True)\n",
    "    kappa = make_param(name='kappa', stdev=np.sqrt(2)/num_qubits, shape=[depth, num_qubits], regularize=False, monitor=True)\n",
    "    phi_2 = make_param(name='phi_2', stdev=np.sqrt(2)/num_qubits, shape=[depth, num_qubits], regularize=False)\n",
    "    theta_2 = make_param(name='theta_2', stdev=np.sqrt(2)/num_qubits, shape=[depth, num_qubits], regularize=False)\n",
    "    rtheta_2 = make_param(name='rtheta_2', stdev=np.sqrt(2)/num_qubits, shape=[depth, num_qubits], regularize=False, monitor=True)\n",
    "\n",
    "    def layer(i, size):\n",
    "        Rgate(rtheta_1[i, 0]) | (q[0])\n",
    "        BSgate(phi_1[i, 0], 0) | (q[0], q[1])\n",
    "        Rgate(rtheta_1[i, 2]) | (q[1])\n",
    "\n",
    "        for j in range(size):\n",
    "            Sgate(r[i, j]) | q[j]\n",
    "\n",
    "        Rgate(rtheta_2[i, 0]) | (q[0])\n",
    "        BSgate(phi_2[i, 0], 0) | (q[0], q[1])\n",
    "        Rgate(rtheta_2[i, 2]) | (q[2])\n",
    "        BSgate(phi_2[i, 2], theta_2[i, 3]) | (q[2], q[3])\n",
    "        Rgate(rtheta_2[i, 1]) | (q[1])\n",
    "        BSgate(phi_2[i, 1], 0) | (q[1], q[2])\n",
    "        Rgate(rtheta_2[i, 0]) | (q[0])\n",
    "        BSgate(phi_2[i, 0], 0) | (q[0], q[1])\n",
    "        Rgate(rtheta_2[i, 0]) | (q[0])\n",
    "        Rgate(rtheta_2[i, 1]) | (q[1])\n",
    "        Rgate(rtheta_2[i, 2]) | (q[2])\n",
    "        Rgate(rtheta_2[i, 3]) | (q[3])\n",
    "        BSgate(phi_2[i, 2], 0) | (q[2], q[3])\n",
    "        Rgate(rtheta_2[i, 2]) | (q[2])\n",
    "        BSgate(phi_2[i, 1], 0) | (q[1], q[2])\n",
    "        Rgate(rtheta_2[i, 1]) | (q[1])\n",
    "\n",
    "        for j in range(size):\n",
    "            Kgate(kappa[i, j]) | q[j]\n",
    "\n",
    "    eng, q = sf.Engine(num_qubits)\n",
    "\n",
    "    with eng:\n",
    "        for i in range(num_qubits):\n",
    "            Dgate(X[:, i], 0.) | q[i]\n",
    "        for d in range(depth):\n",
    "            layer(d, num_qubits)\n",
    "    \n",
    "    num_inputs = X.get_shape().as_list()[0]\n",
    "    state = eng.run('tf', cutoff_dim=10, eval=False, batch_size=num_inputs)\n",
    "    circuit_output, var0 = state.quad_expectation(0)\n",
    "\n",
    "    return circuit_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "myloss:\n",
    "\n",
    "The defined mean-squared loss function. Uses tensorflow's loss function.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "circuit_output (Tensor) - circuit output of network to compare with actual output\n",
    "<br>\n",
    "targets (Tensor) - the actual output\n",
    "\n",
    "Return:\n",
    "\n",
    "The weight mean-squared error float (Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myloss(circuit_output, targets):\n",
    "    return tf.losses.mean_squared_error(labels=circuit_output, predictions=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of regularization function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "myregularizer:\n",
    "\n",
    "The defined regularization (if turned on). Uses tensorflow's neural network class for performing L2 regularization. Essentially, it penalises large values of parameters marked for regularization in make_param() under the circuit() funciton above.\n",
    "\n",
    "Arguments: \n",
    "\n",
    "regularized_params (Tensor) - the keyword 'regularized_params' is mandatory; it's used to find the params that have regularize to True in make_param()\n",
    "\n",
    "Return:\n",
    "\n",
    "The L2 norm (Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myregularizer(regularized_params):\n",
    "    return tf.nn.l2_loss(regularized_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: A function for output predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputs_to_predictions:\n",
    "\n",
    "Used to score a test set and get the predictions for a set of test inputs. First, define how circuit outputs translate to model predictions. The keyword argument circuit_output is mandatory.\n",
    "\n",
    "Arguments:\n",
    "\n",
    "circuit_output (Tensor) - the circuit output from output when testing circuit. May also be defined using tensorflow objects\n",
    "\n",
    "Return:\n",
    "\n",
    "Circuit output predictions (Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputs_to_predictions(circuit_output):\n",
    "    return circuit_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data imported with Pandas and Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data import for training and testing circuit is done with Pandas data frame, and stored and shuffled with numpy data structure. \n",
    "\n",
    "The data set here comes from UCI Forest Fires Dataset (http://archive.ics.uci.edu/ml/datasets/forest%20fires)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pandas.read_csv('FFtrain2.csv', header=0)\n",
    "df_test = pandas.read_csv('FFtest2.csv', header=0)\n",
    "\n",
    "df_train = np.array(df_train)\n",
    "df_test = np.array(df_test)\n",
    "\n",
    "np.random.shuffle(df_train)\n",
    "np.random.shuffle(df_test)\n",
    "\n",
    "X_train = df_train[:, 0:4]\n",
    "Y_train = df_train[:, 4]\n",
    "\n",
    "X_test = df_test[:, 0:4]\n",
    "Y_test = df_test[:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters for the circuit are defined below with a dictionary. 'circuit' is defined by the circuit function above, 'task' specifies the learning task, 'loss' is defined by the loss function, 'optimizer' is specified by the acronym for Stochastic Gradient Descent, 'init_learning_rate' is the learning rate for training, and the 'regularizer' and 'regularization_strength' keys specify the regularization function and strength.\n",
    "\n",
    "All hyperparameters are passed to CircuitLearner to construct the learner that implements training and optimization with the hyperparameters passed to the CircuitLearner object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {'circuit': circuit,\n",
    "               'task': 'supervised',\n",
    "               'loss': myloss,\n",
    "               'optimizer': 'SGD',\n",
    "                # 'regularizer': myregularizer,\n",
    "               # 'regularization_strength': 0.1,\n",
    "               'init_learning_rate': 0.1\n",
    "               }\n",
    "\n",
    "learner = CircuitLearner(hyperparams=hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin training of circuit, passing in the training data set and specifying the number of training steps and batch size per iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.train_circuit(X=X_train, Y=Y_train, steps=steps, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completion of training, test circuit with test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = learner.score_circuit(X=X_test, Y=Y_test,\n",
    "                                   outputs_to_predictions=outputs_to_predictions)\n",
    "print(\"\\nPossible scores to print: {}\".format(list(test_score.keys())))\n",
    "print(\"Accuracy on test set: \", test_score['accuracy'])\n",
    "print(\"Loss on test set: \", test_score['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, run circuit to see output predictions of test input data, after training of circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = learner.run_circuit(X=X_test, outputs_to_predictions=outputs_to_predictions)\n",
    "\n",
    "print(\"\\nPossible outcomes to print: {}\".format(list(outcomes.keys())))\n",
    "print(\"Predictions for new inputs: {}\".format(outcomes['predictions']))\n",
    "print(\"Real outputs for new inputs: {}\".format(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results and analysis are presented in our presentation in quantopo/projects/QGLM/Xanadu/docs/'Quantum Generalized Linear Models.pdf'. This is our proof of concept for a programmable quantum generalized linear model using Xanadu's qumode formulation. Our results show that: \n",
    "\n",
    "(1) That the qumodes formulation with its unique operators can eliminate the need for link functions within linear models by exploiting the geometry of the models and still give good prediction, \n",
    "\n",
    "(2) Better than state-of-the-art prediction for a difficult Tweedie regression dataset (UCI Forest Fire)\n",
    "\n",
    "(3) Around state-of-the-art prediction for a simulated dataset\n",
    "\n",
    "(4) This has the potential to bring statistical modeling into quantum computing, by leveraging the underlying geometry and the connection between model geometry and the geometry of quantum physics.\n",
    "\n",
    "(5) Also a potential avenue through which to implement the homotopy continuation method common in dynamic systems research and some machine learning models (such as homotopy-based LASSO), which take a known problem’s solution and continuously deform it to fit the problem of interest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
